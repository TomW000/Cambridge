Dopamine: 5, 7, 8, 10, 13       
GABA: 0, 10, 16, 37, 43   /   300, 310, 316, 337, 343
Octapamine: 11, 14, 22, 23, 31   /   611, 614, 622, 623, 631
Glutamate: 1, 3, 5, 7, 12   /   901, 903, 905, 907, 912 
Serotonin: 10, 11, 13, 20, 21   /   1210, 1211, 1213, 1220, 1221
Acetylcholin: 0, 7, 9, 10, 14, 17   /   1500, 1507, 1509, 1510, 1514, 1517


5, 7, 8, 10, 13, 300, 310, 316, 337, 343, 611, 614, 622, 623, 631, 901, 903, 905, 907, 912, 1210, 1211, 1213, 1220, 1221, 1500, 1507, 1509, 1510, 1514




pre_compute_embeddings - _quantile_normalization, delete_precomputed_embeddings
set_reference_vector - delete_references, generate_pseudolabels( quantile_normalization )
get_closest_elements - 







'''
def get_embeddings():

    good_idx = [5, 7, 8, 10, 13, 300, 310, 316, 337, 343, 611, 614, 622, 623, 631, 901, 903, 905, 907, 912, 1210, 1211, 1213, 1220, 1221, 1500, 1507, 1509, 1510, 1514, 1517]
    files = get_fnames()
    good_files = [files[idx][0] for idx in good_idx]
    dataset = [good_files[i:i+5] for i in range(0, len(good_idx), 5)]
    good_labels = [files[idx][1] for idx in good_idx]
    close_embeddings = []
    
    for k, neuro in enumerate(dataset):
        X = [load_image(file) for file in dataset]
        images = [X[i][0] for i in range(len(X))]
        coordinates = [(0, X[0][1], X[0][2]), 
                      (0, X[0][1]+5, X[0][2]), 
                      (0, X[0][1], X[0][2]+5), 
                      (0, X[0][1]-5, X[0][2]), 
                      (0, X[0][1], X[0][2]-5)]
        few_shot.delete_precomputed_embeddings() # type: ignore
        few_shot.delete_references() # type: ignore
        if not few_shot.emb_precomputed: # type: ignore
            few_shot.pre_compute_embeddings(images, # type: ignore 
                                            overlap=(0, 0),
                                            padding=(0, 0),
                                            #crop_shape=crop_shape, 
                                            verbose=False,
                                            batch_size=5) # type: ignore
        few_shot.set_reference_vector(list_coords=coordinates) # type: ignore
        distances = (few_shot.get_ds_distances_sameRef(verbose=False) < 0.5) # type: ignore

    if not latent:
        return None, labels
    return np.stack(latent).squeeze(), labels

#----------------------------------------------------------------------------------------------------------------------------------------------------------------------

def diplay_features(embeddings,
                    labels,
                    include_pca=True,
                    pca_nb_components=100,
                    nb_neighbor=5,
                    min_dist=0.01,
                    nb_components=2,
                    metric='correlation'):

    if len(embeddings):

        if include_pca:
            pca = PCA(n_components=pca_nb_components)
            features = pca.fit_transform(embeddings)
        else:
            features = embeddings

        reducer = umap.UMAP(
            n_neighbors=nb_neighbor,
            min_dist=min_dist,
            n_components=nb_components,
            metric=metric
            )
        embedding = reducer.fit_transform(features)

        fig = px.scatter(
            x=embedding[:, 0],
            y=embedding[:, 1],
            color = labels,
            title = f'PCA={include_pca} ({pca_nb_components}) - UMAP (n_neighbors={nb_neighbor}, min_dist={min_dist}, n_components={nb_components}, metric={metric})',
            width=1500,
            height=1000
        )
        fig.show()
    else:
        print("No features were extracted!")


if __name__=='__main__':

    batch_size = int(input('Batch size: '))
    include_pca = bool(input('Include PCA? (Boolean): '))
    if include_pca:
        pca_nb_components = int(input('Number of PCA components: '))
    nb_neighbor = int(input('Number of neighbors: '))
    min_dist = float(input('Minimum distance: '))
    nb_components = int(input('Number of components: '))
    metric = input('Metric: ')
    embeddings, labels = get_embeddings(batch_size)
    diplay_features(embeddings, labels, include_pca, pca_nb_components, nb_neighbor, min_dist, nb_components, metric) 

    embeddings, labels = get_embeddings(batch_size=1)
    diplay_features(embeddings,
                    labels,
                    include_pca=True,
                    pca_nb_components=50,
                    nb_neighbor=30,
                    min_dist=0.1,
                    nb_components=2,
                    metric='cosine')
'''